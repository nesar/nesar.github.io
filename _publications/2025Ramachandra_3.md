---
title: "EAIRA: Establishing a Methodology for Evaluating AI Models as Scientific Research Assistants"
collection: "publications"
permalink: "/publication/2025Ramachandra_3"
excerpt: "[<u><span style="color:blue"> arXiv link </span></u>]()"
date: "2025-01-01"
venue: "arXiv e-prints"
paperurl: "https://doi.org/10.48550/arXiv.2502.20309"
citation: "Cappello, Franck, Madireddy, Sandeep, Underwood, Robert, Getty, Neil, Lee-Ping Chia, Nicholas, <b> Ramachandra, Nesar </b>, Nguyen, Josh, Keceli, Murat, Mallick, Tanwi, Li, Zilinghan, Ngom, Marieme, Zhang, Chenhui, Yanguas-Gil, Angel, Antoniuk, Evan, Kailkhura, Bhavya, Tian, Minyang, Du, Yufeng, Ting, Yuan-Sen, Wells, Azton, Nicolae, Bogdan, Maurya, Avinash, Mustafa Rafique, M., Huerta, Eliu, Li, Bo, Foster, Ian, Stevens, Rick; EAIRA: Establishing a Methodology for Evaluating AI Models as Scientific Research Assistants, arXiv e-prints, 2025"
---


Summary: Recent advancements have positioned AI, and particularly Large Language Models (LLMs), as transformative tools for scientific research, capable of addressing complex tasks that require reasoning, problem-solving, and decision-making. Their exceptional capabilities suggest their potential as scientific research assistants but also highlight the need for holistic, rigorous, and domain-specific evaluation to assess effectiveness in real-world scientific applications. This paper describes a multifac...