---
title: "Physical Benchmarking for AI-Generated Cosmic Web"
collection: publications
permalink: /publication/2021Ramachandra_2
excerpt: '[<u><span style="color:blue"> arXiv link </span></u>](https://arxiv.org/abs/2112.05681)'
date: 2021-11-21
venue: 'Neural Information Processing Systems (NeurIPS) 2021 AI for Science Workshop (2021)'
paperurl: 'https://arxiv.org/abs/2112.05681'
citation: 'Xiaofeng Dong, <b> Nesar Ramachandra </b>, Salman Habib, Katrin Heitmann, Michael Buehlmann, Sandeep Madireddy; Physical Benchmarking for AI-Generated Cosmic Web, Neural Information Processing Systems (NeurIPS) 2021 AI for Science Workshop (2021)'
---


Summary: The potential of deep learning based image-to-image translations has recently drawn a lot of attention; one intriguing possibility is that of generating cosmological predictions with a drastic reduction in computational cost. Such an effort requires optimization of neural networks with loss functions beyond low-order statistics like pixel-wise mean square error, and validation of results beyond simple visual comparisons and summary statistics. In order to study learning-based cosmological mappings, we choose a tractable analytical prescription - the Zel'dovich approximation - modeled using U-Net, a convolutional image translation framework. A comprehensive list of metrics is proposed, including higher-order correlation functions, conservation laws, topological indicators, dynamical robustness, and statistical independence of density fields. We find that the U-Net approach does well with some metrics but has difficulties with others. In addition to validating AI approaches using rigorous physical benchmarks, this study motivates advancements in domain-specific optimization schemes for scientific machine learning.
