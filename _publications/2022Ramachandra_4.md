---
title: "Interpretable Uncertainty Quantification in AI for HEP"
collection: "publications"
permalink: "/publication/2022Ramachandra_4"
excerpt: "[<u><span style="color:blue"> arXiv link </span></u>]()"
date: "2022-01-01"
venue: "arXiv e-prints"
paperurl: "https://doi.org/10.48550/arXiv.2208.03284"
citation: "Chen, Thomas Y., Dey, Biprateep, Ghosh, Aishik, Kagan, Michael, Nord, Brian, <b> Ramachandra, Nesar </b>; Interpretable Uncertainty Quantification in AI for HEP, arXiv e-prints, 2022"
---


Summary: Estimating uncertainty is at the core of performing scientific measurements in HEP: a measurement is not useful without an estimate of its uncertainty. The goal of uncertainty quantification (UQ) is inextricably linked to the question, "how do we physically and statistically interpret these uncertainties?" The answer to this question depends not only on the computational task we aim to undertake, but also on the methods we use for that task. For artificial intelligence (AI) applications in HEP, ...