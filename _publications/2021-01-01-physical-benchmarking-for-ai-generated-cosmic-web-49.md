---
title: "Physical Benchmarking for AI-Generated Cosmic Web"
collection: publications
permalink: /publication/2021-physical-benchmarking-for-ai-generated-cosmic-web
excerpt: '[<u><span style="color:blue">Google Scholar</span></u>](https://scholar.google.com/scholar?q=Physical+Benchmarking+for+AI-Generated+Cosmic+Web)'
date: 2021-01-01
venue: 'arXiv preprint arXiv:2112.05681'
paperurl: 'https://arxiv.org/abs/2112.05681'
citation: 'Xiaofeng Dong and Nesar Ramachandra and Salman Habib and Katrin Heitmann and Michael Buehlmann and Sandeep Madireddy (2021). "Physical Benchmarking for AI-Generated Cosmic Web". arXiv preprint arXiv:2112.05681.'
---

The potential of deep learning based image-to-image translations has recently drawn a lot of attention; one intriguing possibility is that of generating cosmological predictions with a drastic reduction in computational cost. Such an effort requires optimization of neural networks with loss functions beyond low-order statistics like pixel-wise mean square error, and validation of results beyond simple visual comparisons and summary statistics. In order to study learning-based cosmological mappings, we choose a tractable analytical prescription - the Zel'dovich approximation - modeled using U-Net, a convolutional image translation framework. A comprehensive list of metrics is proposed, including higher-order correlation functions, conservation laws, topological indicators, dynamical robustness, and statistical independence of density fields. We find that the U-Net approach does well with some metrics but has difficulties with others. In addition to validating AI approaches using rigorous physical benchmarks, this study motivates advancements in domain-specific optimization schemes for scientific machine learning.
